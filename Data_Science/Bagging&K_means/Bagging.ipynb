{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris = pd.read_csv('Iris.csv',encoding='utf-8') # read iris data for predict to label\n",
    "labels = iris['Species'] # real label of iris data set\n",
    "size = len(iris) # the number of iris data set\n",
    "roundN = 10 # the number of bagging round\n",
    "\n",
    "# read iris bagging dataset (1)~(10) for round 10 \n",
    "samples = []\n",
    "sample = pd.read_csv('Iris_bagging_dataset (1).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (2).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (3).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (4).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (5).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (6).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (7).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (8).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (9).csv',encoding='utf-8')\n",
    "samples.append(sample)\n",
    "sample = pd.read_csv('Iris_bagging_dataset (10).csv',encoding='utf-8')\n",
    "samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predicts = [] # results of predict in each bagging round about iris data(150)\n",
    "\n",
    "# bagging 10 round\n",
    "for i in range(roundN) :\n",
    "    tree_clf = DecisionTreeClassifier(criterion='entropy',random_state=0) # Define Decision Tree Classifier\n",
    "    X = samples[i].iloc[:,1:5] # exclude attribute 'id' and 'Species'\n",
    "    y = samples[i]['Species'] # labels about bagging data set\n",
    "    tree_clf.fit(X,y) # training by using bagging data set(10) which has each 150 data\n",
    "    tree_predicts.append(tree_clf.predict(iris.iloc[:,1:5])) # append results of predict in each bagging round\n",
    "    \n",
    "tree_predicts = np.array(tree_predicts) # type conversion for majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = [] # total results of predicted label(150) by majority voting \n",
    "\n",
    "# Majority bagging\n",
    "for i in range(size) :\n",
    "    # aggregation 10 classifier get from each bagging round and calculate the number of element to each label\n",
    "    result = Counter(tree_predicts[:,i])\n",
    "    \n",
    "    total_predict.append(result.most_common(1)[0][0]) # get the most common predicted label about 150 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       0.96      0.96      0.96        50\n",
      " Iris-virginica       0.96      0.96      0.96        50\n",
      "\n",
      "    avg / total       0.97      0.97      0.97       150\n",
      "\n",
      "Order: setosa, versicolor, virginica\n",
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  2 48]]\n",
      "Accuracy:  0.9733333333333334\n",
      "\n",
      "\n",
      " ** Predict result **\n",
      "                  0\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "5       Iris-setosa\n",
      "6       Iris-setosa\n",
      "7       Iris-setosa\n",
      "8       Iris-setosa\n",
      "9       Iris-setosa\n",
      "10      Iris-setosa\n",
      "11      Iris-setosa\n",
      "12      Iris-setosa\n",
      "13      Iris-setosa\n",
      "14      Iris-setosa\n",
      "15      Iris-setosa\n",
      "16      Iris-setosa\n",
      "17      Iris-setosa\n",
      "18      Iris-setosa\n",
      "19      Iris-setosa\n",
      "20      Iris-setosa\n",
      "21      Iris-setosa\n",
      "22      Iris-setosa\n",
      "23      Iris-setosa\n",
      "24      Iris-setosa\n",
      "25      Iris-setosa\n",
      "26      Iris-setosa\n",
      "27      Iris-setosa\n",
      "28      Iris-setosa\n",
      "29      Iris-setosa\n",
      "..              ...\n",
      "120  Iris-virginica\n",
      "121  Iris-virginica\n",
      "122  Iris-virginica\n",
      "123  Iris-virginica\n",
      "124  Iris-virginica\n",
      "125  Iris-virginica\n",
      "126  Iris-virginica\n",
      "127  Iris-virginica\n",
      "128  Iris-virginica\n",
      "129  Iris-virginica\n",
      "130  Iris-virginica\n",
      "131  Iris-virginica\n",
      "132  Iris-virginica\n",
      "133  Iris-virginica\n",
      "134  Iris-virginica\n",
      "135  Iris-virginica\n",
      "136  Iris-virginica\n",
      "137  Iris-virginica\n",
      "138  Iris-virginica\n",
      "139  Iris-virginica\n",
      "140  Iris-virginica\n",
      "141  Iris-virginica\n",
      "142  Iris-virginica\n",
      "143  Iris-virginica\n",
      "144  Iris-virginica\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "149  Iris-virginica\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(labels,total_predict,\n",
    "                            target_names=['Iris-setosa', \n",
    "                                          'Iris-versicolor', 'Iris-virginica']))\n",
    "\n",
    "# make confusion matrix about real labels and predicted labels by using 'confusion_matrix'\n",
    "confusion = confusion_matrix(labels,total_predict,labels=['Iris-setosa', \n",
    "                                          'Iris-versicolor', 'Iris-virginica'])\n",
    "\n",
    "print(\"Order: setosa, versicolor, virginica\")\n",
    "print(confusion)\n",
    "\n",
    "# accuracy = (TP+TN)/N \n",
    "accuracy = ( confusion[0][0] + confusion[1][1] + confusion[2][2] ) / size\n",
    "print(\"Accuracy: \",accuracy)\n",
    "\n",
    "print(\"\\n\\n ** Predict result **\")\n",
    "total_predict = pd.DataFrame(total_predict)\n",
    "print(total_predict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
